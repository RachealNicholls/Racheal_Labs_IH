{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd49a8f",
   "metadata": {},
   "source": [
    "### gnod_spotify_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3b396",
   "metadata": {},
   "source": [
    "### Data Collection: Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff0e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import config\n",
    "import spotipy\n",
    "import pandas as pd\n",
    "import json\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "\n",
    "#Initialize SpotiPy with user credentials\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id= config.client_id,\n",
    "                                                           client_secret= config.client_secret))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0296ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calling up my stored spotify data\n",
    "df=pd.read_csv('spotify_playlist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0571d40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  artist                   song                                        link  \\\n",
       " 0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       " 1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       " 2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       " 3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       " 4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       " \n",
       "                                                 text  \n",
       " 0  Look at her face, it's a wonderful face  \\r\\nA...  \n",
       " 1  Take it easy with me, please  \\r\\nTouch me gen...  \n",
       " 2  I'll never know why I had to go  \\r\\nWhy I had...  \n",
       " 3  Making somebody happy is a question of give an...  \n",
       " 4  Making somebody happy is a question of give an...  ,\n",
       "              artist           song  \\\n",
       " 57645  Ziggy Marley  Good Old Days   \n",
       " 57646  Ziggy Marley  Hand To Mouth   \n",
       " 57647          Zwan   Come With Me   \n",
       " 57648          Zwan         Desire   \n",
       " 57649          Zwan      Heartsong   \n",
       " \n",
       "                                               link  \\\n",
       " 57645  /z/ziggy+marley/good+old+days_10198588.html   \n",
       " 57646  /z/ziggy+marley/hand+to+mouth_20531167.html   \n",
       " 57647           /z/zwan/come+with+me_20148981.html   \n",
       " 57648                 /z/zwan/desire_20148986.html   \n",
       " 57649              /z/zwan/heartsong_20148991.html   \n",
       " \n",
       "                                                     text  \n",
       " 57645  Irie days come on play  \\r\\nLet the angels fly...  \n",
       " 57646  Power to the workers  \\r\\nMore power  \\r\\nPowe...  \n",
       " 57647  all you need  \\r\\nis something i'll believe  \\...  \n",
       " 57648  northern star  \\r\\nam i frightened  \\r\\nwhere ...  \n",
       " 57649  come in  \\r\\nmake yourself at home  \\r\\ni'm a ...  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(), df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ac34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d218487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spotify_playlist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79919672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\r\\nA...  \n",
       "1  Take it easy with me, please  \\r\\nTouch me gen...  \n",
       "2  I'll never know why I had to go  \\r\\nWhy I had...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b61c723f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57645</th>\n",
       "      <td>Ziggy Marley</td>\n",
       "      <td>Good Old Days</td>\n",
       "      <td>/z/ziggy+marley/good+old+days_10198588.html</td>\n",
       "      <td>Irie days come on play  \\r\\nLet the angels fly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57646</th>\n",
       "      <td>Ziggy Marley</td>\n",
       "      <td>Hand To Mouth</td>\n",
       "      <td>/z/ziggy+marley/hand+to+mouth_20531167.html</td>\n",
       "      <td>Power to the workers  \\r\\nMore power  \\r\\nPowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57647</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Come With Me</td>\n",
       "      <td>/z/zwan/come+with+me_20148981.html</td>\n",
       "      <td>all you need  \\r\\nis something i'll believe  \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57648</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Desire</td>\n",
       "      <td>/z/zwan/desire_20148986.html</td>\n",
       "      <td>northern star  \\r\\nam i frightened  \\r\\nwhere ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57649</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Heartsong</td>\n",
       "      <td>/z/zwan/heartsong_20148991.html</td>\n",
       "      <td>come in  \\r\\nmake yourself at home  \\r\\ni'm a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist           song  \\\n",
       "57645  Ziggy Marley  Good Old Days   \n",
       "57646  Ziggy Marley  Hand To Mouth   \n",
       "57647          Zwan   Come With Me   \n",
       "57648          Zwan         Desire   \n",
       "57649          Zwan      Heartsong   \n",
       "\n",
       "                                              link  \\\n",
       "57645  /z/ziggy+marley/good+old+days_10198588.html   \n",
       "57646  /z/ziggy+marley/hand+to+mouth_20531167.html   \n",
       "57647           /z/zwan/come+with+me_20148981.html   \n",
       "57648                 /z/zwan/desire_20148986.html   \n",
       "57649              /z/zwan/heartsong_20148991.html   \n",
       "\n",
       "                                                    text  \n",
       "57645  Irie days come on play  \\r\\nLet the angels fly...  \n",
       "57646  Power to the workers  \\r\\nMore power  \\r\\nPowe...  \n",
       "57647  all you need  \\r\\nis something i'll believe  \\...  \n",
       "57648  northern star  \\r\\nam i frightened  \\r\\nwhere ...  \n",
       "57649  come in  \\r\\nmake yourself at home  \\r\\ni'm a ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d8fa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57650, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fdecf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist    0\n",
       "song      0\n",
       "link      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dde3d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.sample(5000).drop('link', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf5ff69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Culture Club</td>\n",
       "      <td>Stormkeeper</td>\n",
       "      <td>Ooh I have love sweeter than lies  \\r\\nGave yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barbra Streisand</td>\n",
       "      <td>Draw Me A Circle</td>\n",
       "      <td>Draw me a circle that's perfectly round  \\r\\nO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UB40</td>\n",
       "      <td>You Could Meet Somebody</td>\n",
       "      <td>[Chorus]  \\r\\nYou could meet somebody, you nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Beatles</td>\n",
       "      <td>Misery</td>\n",
       "      <td>The world is treating me bad...Misery.  \\r\\nI'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Used</td>\n",
       "      <td>Burning Down The House</td>\n",
       "      <td>Watch out,  \\r\\nYou might get what you're afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pearl Jam</td>\n",
       "      <td>Red Mosquito</td>\n",
       "      <td>Watched from the window with a red mosquito......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Natalie Cole</td>\n",
       "      <td>Livin' For Love</td>\n",
       "      <td>Who do you love when your heart has had enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Demi Lovato</td>\n",
       "      <td>Bee Song</td>\n",
       "      <td>Sis boom buzz  \\r\\nSis boom buzz  \\r\\nYou hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Genesis</td>\n",
       "      <td>If That's What You Need</td>\n",
       "      <td>Talking makes us human that's what I was told ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Utopia</td>\n",
       "      <td>That's Not Right</td>\n",
       "      <td>If you don't feel like dancing tonight  \\r\\nWe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist                     song  \\\n",
       "0      Culture Club              Stormkeeper   \n",
       "1  Barbra Streisand         Draw Me A Circle   \n",
       "2              UB40  You Could Meet Somebody   \n",
       "3       The Beatles                   Misery   \n",
       "4              Used   Burning Down The House   \n",
       "5         Pearl Jam             Red Mosquito   \n",
       "6      Natalie Cole          Livin' For Love   \n",
       "7       Demi Lovato                 Bee Song   \n",
       "8           Genesis  If That's What You Need   \n",
       "9            Utopia         That's Not Right   \n",
       "\n",
       "                                                text  \n",
       "0  Ooh I have love sweeter than lies  \\r\\nGave yo...  \n",
       "1  Draw me a circle that's perfectly round  \\r\\nO...  \n",
       "2  [Chorus]  \\r\\nYou could meet somebody, you nev...  \n",
       "3  The world is treating me bad...Misery.  \\r\\nI'...  \n",
       "4  Watch out,  \\r\\nYou might get what you're afte...  \n",
       "5  Watched from the window with a red mosquito......  \n",
       "6  Who do you love when your heart has had enough...  \n",
       "7  Sis boom buzz  \\r\\nSis boom buzz  \\r\\nYou hear...  \n",
       "8  Talking makes us human that's what I was told ...  \n",
       "9  If you don't feel like dancing tonight  \\r\\nWe...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26eb5b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ooh I have love sweeter than lies  \\r\\nGave you no reason not to decide  \\r\\nSay you are leaving, you've got too much pride  \\r\\nIt's not love if you have it to hide it  \\r\\n  \\r\\nOh woe who is the man  \\r\\nWho puts waves on the sand  \\r\\nIt's the stormkeeper, stormkeeper  \\r\\nLiven my life  \\r\\nWhen I need to survive  \\r\\nIs the storm keeping you warm  \\r\\nKeeping you warm  \\r\\n  \\r\\nOh I have cried so many times  \\r\\nBut only for things that never were mine  \\r\\nHeaven is sweet, love is unkind  \\r\\nThoughts are twisted inside of your mind  \\r\\n  \\r\\nDon't let them tell you  \\r\\nThat this love is wrong  \\r\\nAnd don't let them fool you  \\r\\nThat this love can't go on\\r\\n\\r\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc76d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a0c4186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865afecc",
   "metadata": {},
   "source": [
    "### Text Cleaning / Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2359525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower().replace(r'^\\w\\s', ' ').replace(r'\\n', ' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e78451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenization(txt):\n",
    "    tokens = nltk.word_tokenize(txt)\n",
    "    stemming = [stemmer.stem(w) for w in tokens]\n",
    "    return \" \".join(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5c1ece2",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/rachealnicholls/nltk_data'\n    - '/Users/rachealnicholls/anaconda3/nltk_data'\n    - '/Users/rachealnicholls/anaconda3/share/nltk_data'\n    - '/Users/rachealnicholls/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: tokenization(x))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: tokenization(x))\n",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m, in \u001b[0;36mtokenization\u001b[0;34m(txt)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenization\u001b[39m(txt):\n\u001b[0;32m----> 6\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(txt)\n\u001b[1;32m      7\u001b[0m     stemming \u001b[38;5;241m=\u001b[39m [stemmer\u001b[38;5;241m.\u001b[39mstem(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tokens]\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stemming)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m _open(resource_url)\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, path \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/rachealnicholls/nltk_data'\n    - '/Users/rachealnicholls/anaconda3/nltk_data'\n    - '/Users/rachealnicholls/anaconda3/share/nltk_data'\n    - '/Users/rachealnicholls/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95fc3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4945e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidvector = TfidfVectorizer(analyzer='word',stop_words='english')\n",
    "matrix = tfidvector.fit_transform(df['text'])\n",
    "similarity = cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1794772",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6221770",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df['song'] == 'Crying Over You']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc3827c",
   "metadata": {},
   "source": [
    "### User Interaction and Recommendations:*\n",
    "   Allow users input their preferences, through URL or keywords related to their interests.\n",
    "    Use the input desciption for recommendation.\n",
    "    Rank the playlist based on similarity scores and present the top recommendations to  user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5aaa2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(song_df):\n",
    "    idx = df[df['song'] == song_df].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[idx])),reverse=True,key=lambda x:x[1])\n",
    "    \n",
    "    songs = []\n",
    "    for m_id in distances[1:21]:\n",
    "        songs.append(df.iloc[m_id[0]].song)\n",
    "        \n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "216c25bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m recommendation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrying Over You\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m, in \u001b[0;36mrecommendation\u001b[0;34m(song_df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommendation\u001b[39m(song_df):\n\u001b[0;32m----> 2\u001b[0m     idx \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msong\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m song_df]\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(similarity[idx])),reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x:x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      5\u001b[0m     songs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5175\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[1;32m   5173\u001b[0m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[1;32m   5174\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mcast_scalar_indexer(key)\n\u001b[0;32m-> 5175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m getitem(key)\n\u001b[1;32m   5177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   5178\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[1;32m   5179\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[1;32m   5180\u001b[0m     result \u001b[38;5;241m=\u001b[39m getitem(key)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "recommendation('Crying Over You')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18192437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(similarity,open('similarity.pkl','wb'))\n",
    "pickle.dump(df,open('df.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7edcf20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718f7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
